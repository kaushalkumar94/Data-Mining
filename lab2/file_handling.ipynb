{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4dd5c2e-21d7-4d78-87c5-4442effa7647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5187c3-f569-42b3-b479-68c8b4dcce04",
   "metadata": {},
   "source": [
    "## CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c8b1e06-bdaf-4100-b979-be3ba75e1858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    John       Doe                 120 jefferson st.  \\\n",
      "0                   Jack  McGinnis                      220 hobo Av.   \n",
      "1          John \"Da Man\"    Repici                 120 Jefferson St.   \n",
      "2                Stephen     Tyler  7452 Terrace \"At the Plaza\" road   \n",
      "3                    NaN  Blankman                               NaN   \n",
      "4  Joan \"the bone\", Anne       Jet               9th, at Terrace plc   \n",
      "\n",
      "     Riverside   NJ   08075  \n",
      "0        Phila   PA    9119  \n",
      "1    Riverside   NJ    8075  \n",
      "2     SomeTown   SD   91234  \n",
      "3     SomeTown   SD     298  \n",
      "4  Desert City   CO     123  \n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path of the CSV file\n",
    "# Use a raw string (r\"\") to avoid issues with backslashes in Windows paths\n",
    "file_path = r\"D:\\CODING\\data mining\\lab 2\\dataset\\addresses.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e9326b-612e-4b82-8177-f515a920cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    John       Doe                 120 jefferson st.  \\\n",
      "0                   Jack  McGinnis                      220 hobo Av.   \n",
      "1          John \"Da Man\"    Repici                 120 Jefferson St.   \n",
      "2                Stephen     Tyler  7452 Terrace \"At the Plaza\" road   \n",
      "3                    NaN  Blankman                               NaN   \n",
      "4  Joan \"the bone\", Anne       Jet               9th, at Terrace plc   \n",
      "\n",
      "     Riverside   NJ   08075  \n",
      "0        Phila   PA    9119  \n",
      "1    Riverside   NJ    8075  \n",
      "2     SomeTown   SD   91234  \n",
      "3     SomeTown   SD     298  \n",
      "4  Desert City   CO     123  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a08fa8-d35a-4858-bb2f-3d103202378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   John               4 non-null      object\n",
      " 1   Doe                5 non-null      object\n",
      " 2   120 jefferson st.  4 non-null      object\n",
      " 3   Riverside          5 non-null      object\n",
      " 4    NJ                5 non-null      object\n",
      " 5    08075             5 non-null      int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 372.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c02c18b-52db-45c9-a996-5c69658b757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              08075\n",
      "count      5.000000\n",
      "mean   21769.800000\n",
      "std    39059.209909\n",
      "min      123.000000\n",
      "25%      298.000000\n",
      "50%     8075.000000\n",
      "75%     9119.000000\n",
      "max    91234.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c993ac8-1272-4a9e-8f06-827c0863feb7",
   "metadata": {},
   "source": [
    "## EXCEL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54886c61-519a-4cd7-9612-99d2ed910b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0 First Name   Last Name  Gender        Country  Age  \\\n",
      "0             1      Dulce       Abril  Female  United States   32   \n",
      "1             2       Mara   Hashimoto  Female  Great Britain   25   \n",
      "2             3     Philip        Gent    Male         France   36   \n",
      "3             4   Kathleen      Hanner  Female  United States   25   \n",
      "4             5    Nereida     Magwood  Female  United States   58   \n",
      "..          ...        ...         ...     ...            ...  ...   \n",
      "995         996       Roma  Lafollette  Female  United States   34   \n",
      "996         997     Felisa        Cail  Female  United States   28   \n",
      "997         998   Demetria       Abbey  Female  United States   32   \n",
      "998         999     Jeromy        Danz    Male  United States   39   \n",
      "999        1000   Rasheeda      Alkire  Female  United States   29   \n",
      "\n",
      "           Date    Id  \n",
      "0    15/10/2017  1562  \n",
      "1    16/08/2016  1582  \n",
      "2    21/05/2015  2587  \n",
      "3    15/10/2017  3549  \n",
      "4    16/08/2016  2468  \n",
      "..          ...   ...  \n",
      "995  15/10/2017  2654  \n",
      "996  16/08/2016  6525  \n",
      "997  21/05/2015  3265  \n",
      "998  15/10/2017  3265  \n",
      "999  16/08/2016  6125  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path of the Excel file\n",
    "# Raw string is used to correctly handle Windows file paths\n",
    "file_path = r\"D:\\CODING\\data mining\\lab 2\\dataset\\file_example_XLSX_1000.xlsx\"\n",
    "\n",
    "# Read the Excel file into a Pandas DataFrame\n",
    "# By default, the first sheet is read\n",
    "df_excel = pd.read_excel(file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73988ab6-23a1-4023-886d-0b5f810486f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 First Name  Last Name  Gender        Country  Age        Date  \\\n",
      "0           1      Dulce      Abril  Female  United States   32  15/10/2017   \n",
      "1           2       Mara  Hashimoto  Female  Great Britain   25  16/08/2016   \n",
      "2           3     Philip       Gent    Male         France   36  21/05/2015   \n",
      "3           4   Kathleen     Hanner  Female  United States   25  15/10/2017   \n",
      "4           5    Nereida    Magwood  Female  United States   58  16/08/2016   \n",
      "\n",
      "     Id  \n",
      "0  1562  \n",
      "1  1582  \n",
      "2  2587  \n",
      "3  3549  \n",
      "4  2468  \n"
     ]
    }
   ],
   "source": [
    "print(df_excel.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00050615-78f9-493f-9b27-f5413d138171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1000 non-null   int64 \n",
      " 1   First Name  1000 non-null   object\n",
      " 2   Last Name   1000 non-null   object\n",
      " 3   Gender      1000 non-null   object\n",
      " 4   Country     1000 non-null   object\n",
      " 5   Age         1000 non-null   int64 \n",
      " 6   Date        1000 non-null   object\n",
      " 7   Id          1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_excel.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35545beb-f825-4208-9ce5-f16f531e91c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0          Age           Id\n",
      "count  1000.000000  1000.000000  1000.000000\n",
      "mean    500.500000    33.260000  4717.720000\n",
      "std     288.819436     8.353573  2368.340592\n",
      "min       1.000000    21.000000  1258.000000\n",
      "25%     250.750000    26.000000  2587.000000\n",
      "50%     500.500000    32.000000  3574.000000\n",
      "75%     750.250000    38.000000  6540.000000\n",
      "max    1000.000000    58.000000  9654.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_excel.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a9542-9188-48cd-8735-68da25ca13e2",
   "metadata": {},
   "source": [
    "## TEXT file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f40bf91-04ff-4195-8a7d-e2d7262921e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text\n",
      "0     The Project Gutenberg eBook of Frankenstein; O...\n",
      "1                                                      \n",
      "2     This ebook is for the use of anyone anywhere i...\n",
      "3     most other parts of the world at no cost and w...\n",
      "4     whatsoever. You may copy it, give it away or r...\n",
      "...                                                 ...\n",
      "7731  This website includes information about Projec...\n",
      "7732  including how to make donations to the Project...\n",
      "7733  Archive Foundation, how to help produce our ne...\n",
      "7734  subscribe to our email newsletter to hear abou...\n",
      "7735                                                   \n",
      "\n",
      "[7736 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path of the text file\n",
    "# Raw string is used to correctly handle Windows file paths\n",
    "file_path = r\"D:\\CODING\\data mining\\lab 2\\dataset\\frankenstein.txt\"\n",
    "\n",
    "# Open the text file using Python's built-in file handling\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read all lines from the text file\n",
    "    lines = file.read().splitlines()\n",
    "\n",
    "# Convert the text data into a Pandas DataFrame\n",
    "# Each line of the text file becomes a separate row\n",
    "df_txt = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c9c797-cdfa-4b79-95cd-23564abad1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  The Project Gutenberg eBook of Frankenstein; O...\n",
      "1                                                   \n",
      "2  This ebook is for the use of anyone anywhere i...\n",
      "3  most other parts of the world at no cost and w...\n",
      "4  whatsoever. You may copy it, give it away or r...\n",
      "5  of the Project Gutenberg License included with...\n",
      "6  at www.gutenberg.org. If you are not located i...\n",
      "7  you will have to check the laws of the country...\n",
      "8                           before using this eBook.\n",
      "9                                                   \n"
     ]
    }
   ],
   "source": [
    "print(df_txt.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de45688-6046-4e72-bc2e-a12837882305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 7736\n"
     ]
    }
   ],
   "source": [
    "print(\"Total lines:\", len(df_txt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50f520-b388-4d75-87bf-7a85e6c7629b",
   "metadata": {},
   "source": [
    "## JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07e7322a-3182-4c2d-a1e3-044847d2a052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0    13300000  7420         4          2        3      yes        no       no   \n",
      "1    12250000  8960         4          4        4      yes        no       no   \n",
      "2    12250000  9960         3          2        2      yes        no      yes   \n",
      "3    12215000  7500         4          2        2      yes        no      yes   \n",
      "4    11410000  7420         4          1        2      yes       yes      yes   \n",
      "..        ...   ...       ...        ...      ...      ...       ...      ...   \n",
      "540   1820000  3000         2          1        1      yes        no      yes   \n",
      "541   1767150  2400         3          1        1       no        no       no   \n",
      "542   1750000  3620         2          1        1      yes        no       no   \n",
      "543   1750000  2910         3          1        1       no        no       no   \n",
      "544   1750000  3850         3          1        2      yes        no       no   \n",
      "\n",
      "    hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0                no             yes        2      yes        furnished  \n",
      "1                no             yes        3       no        furnished  \n",
      "2                no              no        2      yes   semi-furnished  \n",
      "3                no             yes        3      yes        furnished  \n",
      "4                no             yes        2       no        furnished  \n",
      "..              ...             ...      ...      ...              ...  \n",
      "540              no              no        2       no      unfurnished  \n",
      "541              no              no        0       no   semi-furnished  \n",
      "542              no              no        0       no      unfurnished  \n",
      "543              no              no        0       no        furnished  \n",
      "544              no              no        0       no      unfurnished  \n",
      "\n",
      "[545 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path of the JSON file\n",
    "# Raw string is used to correctly handle Windows file paths\n",
    "file_path = r\"D:\\CODING\\data mining\\lab 2\\dataset\\price.json\"\n",
    "\n",
    "# Read the JSON file into a Pandas DataFrame\n",
    "# Works best when JSON is in list-of-records format\n",
    "df_json = pd.read_json(file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa011634-17ce-4ddf-9f23-6e39812ca2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price   area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000   7420         4          2        3      yes        no       no   \n",
      "1  12250000   8960         4          4        4      yes        no       no   \n",
      "2  12250000   9960         3          2        2      yes        no      yes   \n",
      "3  12215000   7500         4          2        2      yes        no      yes   \n",
      "4  11410000   7420         4          1        2      yes       yes      yes   \n",
      "5  10850000   7500         3          3        1      yes        no      yes   \n",
      "6  10150000   8580         4          3        4      yes        no       no   \n",
      "7  10150000  16200         5          3        2      yes        no       no   \n",
      "8   9870000   8100         4          1        2      yes       yes      yes   \n",
      "9   9800000   5750         3          2        4      yes       yes       no   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "1              no             yes        3       no        furnished  \n",
      "2              no              no        2      yes   semi-furnished  \n",
      "3              no             yes        3      yes        furnished  \n",
      "4              no             yes        2       no        furnished  \n",
      "5              no             yes        2      yes   semi-furnished  \n",
      "6              no             yes        2      yes   semi-furnished  \n",
      "7              no              no        0       no      unfurnished  \n",
      "8              no             yes        2      yes        furnished  \n",
      "9              no             yes        1      yes      unfurnished  \n"
     ]
    }
   ],
   "source": [
    "print(df_json.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0398ca1-27d9-4b15-96c6-f0ad0b87e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              price          area    bedrooms   bathrooms     stories  \\\n",
      "count  5.450000e+02    545.000000  545.000000  545.000000  545.000000   \n",
      "mean   4.766729e+06   5150.541284    2.965138    1.286239    1.805505   \n",
      "std    1.870440e+06   2170.141023    0.738064    0.502470    0.867492   \n",
      "min    1.750000e+06   1650.000000    1.000000    1.000000    1.000000   \n",
      "25%    3.430000e+06   3600.000000    2.000000    1.000000    1.000000   \n",
      "50%    4.340000e+06   4600.000000    3.000000    1.000000    2.000000   \n",
      "75%    5.740000e+06   6360.000000    3.000000    2.000000    2.000000   \n",
      "max    1.330000e+07  16200.000000    6.000000    4.000000    4.000000   \n",
      "\n",
      "          parking  \n",
      "count  545.000000  \n",
      "mean     0.693578  \n",
      "std      0.861586  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      1.000000  \n",
      "max      3.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_json.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "062736ac-a9af-4e8d-a186-aff8475f3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " print(df_json.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34403317-c204-43c0-81ba-51cbea030698",
   "metadata": {},
   "source": [
    "## Opening data by url on python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5eaa659-9342-41d1-b66e-935671462ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Downloading lxml-6.0.2-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 479.2 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 0.8/4.0 MB 176.6 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 155.8 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 1.3/4.0 MB 145.3 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 1.6/4.0 MB 132.9 kB/s eta 0:00:19\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 1.8/4.0 MB 132.5 kB/s eta 0:00:17\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 2.1/4.0 MB 136.4 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 128.8 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 2.6/4.0 MB 129.2 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 130.7 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 130.7 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 130.7 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 130.7 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 130.7 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 130.7 kB/s eta 0:00:09\n",
      "   ------------------------------- -------- 3.1/4.0 MB 134.1 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 3.1/4.0 MB 134.1 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 3.1/4.0 MB 134.1 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 3.1/4.0 MB 134.1 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 3.1/4.0 MB 134.1 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 3.1/4.0 MB 134.1 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 3.4/4.0 MB 138.4 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 3.4/4.0 MB 138.4 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 3.4/4.0 MB 138.4 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 3.4/4.0 MB 138.4 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 3.4/4.0 MB 138.4 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 3.4/4.0 MB 138.4 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 3.7/4.0 MB 142.7 kB/s eta 0:00:03\n",
      "   ---------------------------------------  3.9/4.0 MB 141.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 142.3 kB/s  0:00:26\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb095e82-5753-4d6a-959b-637c54276710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Wikipedia URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
    "\n",
    "# Send request with browser-like User-Agent\n",
    "response = requests.get(\n",
    "    url,\n",
    "    headers={\"User-Agent\": \"Mozilla/5.0\"}\n",
    ")\n",
    "\n",
    "# Read HTML tables from the page content\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "# Select the first table\n",
    "df_wiki = tables[0]\n",
    "\n",
    "# Display data in tabular form\n",
    "print(df_wiki)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b28f75-08ca-49b2-bea2-f2b9f6236ac9",
   "metadata": {},
   "source": [
    "## Read pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2d71ee7-1190-44d5-8f66-0084dbcd50cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.9)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (20251230)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (12.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (46.0.4)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26eaa0a0-3c45-4068-b43c-e5ac44effe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\kaush\\AppData\\Local\\Temp\\ipykernel_10972\\3794167344.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  file_path = \"D:\\STUDY\\GATE\\PYQS\\CS\\CS22025.pdf\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              PDF_Text\n",
      "0    Computer Science and Information Technology (CS2)\n",
      "1                                     General Aptitude\n",
      "2                        Q.1 – Q.5 Carry ONE mark Each\n",
      "3    Q.1 Despite his initial hesitation, Rehman’s _...\n",
      "4                           the project never wavered.\n",
      "..                                                 ...\n",
      "743  Q.65 The unit interval (0,1) is divided at a p...\n",
      "744               in ℝ into two disjoint subintervals.\n",
      "745  The expected length of the subinterval that co...\n",
      "746                         off to two decimal places)\n",
      "747    Organising Institute: IIT Roorkee Page 48 of 48\n",
      "\n",
      "[748 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# PDF file path (can be local or URL-downloaded)\n",
    "file_path = \"D:\\STUDY\\GATE\\PYQS\\CS\\CS22025.pdf\"\n",
    "\n",
    "# List to store extracted text\n",
    "data = []\n",
    "\n",
    "# Open the PDF file\n",
    "with pdfplumber.open(file_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            for line in text.split(\"\\n\"):\n",
    "                data.append([line])\n",
    "\n",
    "# Convert extracted text into DataFrame\n",
    "df_pdf = pd.DataFrame(data, columns=[\"PDF_Text\"])\n",
    "\n",
    "# Display PDF data as table\n",
    "print(df_pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b1903-2f99-46df-908b-f0131c25277a",
   "metadata": {},
   "source": [
    "## Read PPTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "922b2d92-ad90-4042-8b44-4c129f16b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-pptx in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-pptx) (12.1.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-pptx) (3.2.9)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-pptx) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-pptx) (4.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-pptx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46c14da4-49ec-4a9e-b8d0-369d816a73e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Slide_Number                                         Slide_Text\n",
      "0             1                                        Lorem ipsum\n",
      "1             1  Lorem ipsum dolor sit amet, consectetur adipis...\n",
      "2             2                                              Chart\n",
      "3             3                                              Table\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "import pandas as pd\n",
    "\n",
    "# PPT file path\n",
    "file_path = \"D:\\\\CODING\\\\data mining\\\\lab 2\\\\dataset\\\\file_example_PPT_250kB.pptx\"\n",
    "\n",
    "# Load the PowerPoint file\n",
    "presentation = Presentation(file_path)\n",
    "\n",
    "# List to store slide text\n",
    "data = []\n",
    "\n",
    "# Extract text from each slide\n",
    "for slide_number, slide in enumerate(presentation.slides, start=1):\n",
    "    for shape in slide.shapes:\n",
    "        if shape.has_text_frame:\n",
    "            data.append([slide_number, shape.text])\n",
    "\n",
    "# Convert extracted text into DataFrame\n",
    "df_ppt = pd.DataFrame(data, columns=[\"Slide_Number\", \"Slide_Text\"])\n",
    "\n",
    "# Display PPT data as table\n",
    "print(df_ppt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393fb48-8dc5-43a8-b774-ab18820f133b",
   "metadata": {},
   "source": [
    "## Opening text file without pyhton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a805e52a-4adc-4f81-be05-524ae5fc9af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Frankenstein; Or, The Modern Prometheus\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before\n"
     ]
    }
   ],
   "source": [
    "with open(r\"D:\\CODING\\data mining\\lab 2\\dataset\\frankenstein.txt\", \n",
    "          \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(content[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c68196-4bbb-4e96-882c-62e7473a8a0c",
   "metadata": {},
   "source": [
    "## Opening Multimedia file such as image , video , audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07954993-5e80-438a-9046-bbd043cee744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\kaush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (12.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d09a8046-3744-4539-981b-ed6ed5e53af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Use raw string to avoid path errors\n",
    "file_path = r\"D:\\CODING\\data mining\\lab 2\\dataset\\Screenshot 2026-02-01 150322.png\"\n",
    "\n",
    "# Open the image\n",
    "img = Image.open(file_path)\n",
    "\n",
    "# Display the image\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa38e13-dc92-455d-91cc-fe4c4e6027b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a1d53a8-7fe4-4fb2-a2c9-0ab233acf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Correct image path\n",
    "file_path = r\"D:\\CODING\\data mining\\lab 2\\dataset\\Screenshot 2026-02-01 150322.png\"\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(file_path)\n",
    "\n",
    "# Display image in a window\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead715e-aaf4-4617-8def-73ab3456ee25",
   "metadata": {},
   "source": [
    "## Reading data from database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bfbfa-113a-4b5b-ae67-1b674a607354",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mysql-connector-python pandas sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2b334-42f9-41cd-8c05-e90a3a5dd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "username = \"root\"\n",
    "password = \"password\"\n",
    "host = \"localhost\"\n",
    "database = \"test_db\"\n",
    "\n",
    "# Create database connection engine\n",
    "engine = create_engine(\n",
    "    f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\"\n",
    ")\n",
    "\n",
    "# SQL query to fetch data\n",
    "query = \"SELECT * FROM employees\"\n",
    "\n",
    "# Read data from database into DataFrame\n",
    "df_db = pd.read_sql(query, engine)\n",
    "\n",
    "# Display data as table\n",
    "print(df_db)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
